import sys
import platform
import subprocess
import warnings

# ==================== ç»ˆææ ¸å¿ƒï¼šå¯¼å…¥torchå‰å…ˆé…ç½®å…¨å±€è¿‡æ»¤è§„åˆ™ ====================
# è§„åˆ™1ï¼šå…¨å±€æ¨¡ç³ŠåŒ¹é…è­¦å‘Šæ ¸å¿ƒå…³é”®è¯ï¼ˆè¦†ç›–æ‰€æœ‰æ¨¡å—ï¼‰
warnings.filterwarnings(
    "ignore",
    message=r"CUDA capability sm_120 is not compatible",
    category=UserWarning
)
# è§„åˆ™2ï¼šå®šå‘è¿‡æ»¤torch.cudaæ¨¡å—çš„æ‰€æœ‰UserWarningï¼ˆåŒé‡ä¿é™©ï¼‰
warnings.filterwarnings(
    "ignore",
    category=UserWarning,
    module=r"torch\.cuda"
)

# æ­¤æ—¶å†å¯¼å…¥torchï¼Œè¿‡æ»¤è§„åˆ™å·²ç”Ÿæ•ˆï¼Œè­¦å‘Šè¢«ç›´æ¥æ‹¦æˆª
import torch

# ==================== å¼ºåˆ¶åˆå§‹åŒ–CUDAï¼ˆè§¦å‘å‰©ä½™æ½œåœ¨è­¦å‘Šå¹¶æ‹¦æˆªï¼‰====================
# æå‰æ‰§è¡ŒCUDAåˆå§‹åŒ–ï¼Œè®©æ‰€æœ‰ç›¸å…³è­¦å‘Šåœ¨æ£€æµ‹å‰è§¦å‘å¹¶è¢«è¿‡æ»¤
try:
    torch.cuda.is_available()
except:
    pass

def get_python_basic_info():
    """è·å–PythonåŸºç¡€ç¯å¢ƒå’Œç³»ç»Ÿä¿¡æ¯"""
    py_full_ver = sys.version
    py_short_ver = sys.version.split()[0]
    os_info = platform.platform()
    arch_info = platform.architecture()[0]

    print("=" * 60)
    print("ğŸ” Python åŸºç¡€ç¯å¢ƒä¿¡æ¯")
    print("=" * 60)
    print(f"Python å®Œæ•´ç‰ˆæœ¬ï¼š{py_full_ver}")
    print(f"Python æ ¸å¿ƒç‰ˆæœ¬ï¼š{py_short_ver}")
    print(f"è¿è¡Œæ“ä½œç³»ç»Ÿï¼š{os_info}")
    print(f"ç³»ç»Ÿæ¶æ„ï¼š{arch_info}")
    print("=" * 60)

def get_single_pkg_ver(pkg_name):
    """è·å–å•ä¸ªPythonåŒ…çš„ç‰ˆæœ¬ï¼ˆå…¼å®¹å¸¸è§„åŒ…+Hugging Faceç”Ÿæ€åŒ…ï¼‰"""
    try:
        # æ–¹æ¡ˆ1ï¼šä¼˜å…ˆä½¿ç”¨importlib.metadataï¼ˆPython 3.8+ å†…ç½®ï¼Œæœ€å¯é ï¼‰
        from importlib.metadata import version, PackageNotFoundError
        try:
            return version(pkg_name)
        except PackageNotFoundError:
            # æ–¹æ¡ˆ2ï¼šå¤‡ç”¨æ–¹æ¡ˆï¼Œå…¼å®¹è€ç‰ˆæœ¬Python
            import importlib
            pkg_module = importlib.import_module(pkg_name)
            return pkg_module.__version__ if hasattr(pkg_module, "__version__") else "âš ï¸  ç‰ˆæœ¬å·æœªæ‰¾åˆ°"
    
    except ImportError:
        return "âŒ æœªå®‰è£…/å¯¼å…¥å¤±è´¥"
    except AttributeError:
        return "âš ï¸  åŒ…æ— å…¬å¼€ç‰ˆæœ¬å·"
    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)[:40]}..."

def get_cuda_info():
    """è·å–ç³»ç»ŸCUDAå’Œnvccçš„ç‰ˆæœ¬ä¿¡æ¯"""
    cuda_ver = "âŒ æœªå®‰è£…/ä¸å¯ç”¨"
    nvcc_ver = "âŒ æœªå®‰è£…/ä¸å¯ç”¨"

    # æ£€æµ‹nvccç‰ˆæœ¬
    try:
        result = subprocess.check_output(
            ["nvcc", "--version"], 
            stderr=subprocess.STDOUT, 
            text=True
        )
        for line in result.splitlines():
            if "release" in line:
                nvcc_ver = line.strip().split(",")[1].strip()
                break
    except (subprocess.CalledProcessError, FileNotFoundError):
        pass

    # æ£€æµ‹ç³»ç»ŸCUDA Toolkitè·¯å¾„
    try:
        result = subprocess.check_output(
            ["ls", "/usr/local/"], 
            stderr=subprocess.STDOUT, 
            text=True
        )
        for line in result.splitlines():
            if line.startswith("cuda-"):
                cuda_ver = line.split("-")[1]
                break
    except:
        pass

    return cuda_ver, nvcc_ver

def check_pytorch_cuda_status():
    """PyTorchä¸“å±CUDAåŠ é€ŸçŠ¶æ€æ£€æµ‹ï¼ˆæ ¸å¿ƒGPUéªŒè¯ï¼‰"""
    print("\nâš¡ PyTorch CUDA åŠ é€ŸçŠ¶æ€æ£€æµ‹")
    print("-" * 60)
    try:
        cuda_available = torch.cuda.is_available()
        print(f"CUDA å¯ç”¨çŠ¶æ€    ï¼š{'âœ… å¯ç”¨' if cuda_available else 'âŒ ä¸å¯ç”¨'}")
        if cuda_available:
            print(f"PyTorchç»‘å®šCUDAç‰ˆæœ¬ï¼š{torch.version.cuda}")
            print(f"å¯ç”¨GPUè®¾å¤‡æ•°é‡  ï¼š{torch.cuda.device_count()}")
            print(f"ä¸»GPUè®¾å¤‡åç§°    ï¼š{torch.cuda.get_device_name(0)}")
    except Exception as e:
        print(f"âŒ CUDAçŠ¶æ€æ£€æµ‹å¤±è´¥: {str(e)[:50]}...")
    print("-" * 60)

def batch_check_packages(pkg_list):
    """æ‰¹é‡æ£€æŸ¥æŒ‡å®šåŒ…çš„ç‰ˆæœ¬ï¼ˆç»Ÿä¸€ç®¡ç†ï¼ŒæŒ‰è‡ªå®šä¹‰é¡ºåºæ˜¾ç¤ºï¼‰"""
    print("\nğŸ“¦ ç¬¬ä¸‰æ–¹ä¾èµ–åŒ…ç‰ˆæœ¬æ£€æµ‹ï¼ˆå«PyTorchç”Ÿæ€ï¼‰")
    print("-" * 60)
    # ç›´æ¥æŒ‰ä¼ å…¥çš„åˆ—è¡¨é¡ºåºéå†ï¼Œä¸å†æ’åº
    for pkg in pkg_list:
        ver = get_single_pkg_ver(pkg)
        print(f"{pkg.ljust(15)}: {ver}")

    # å•ç‹¬æ£€æµ‹ç³»ç»Ÿçº§CUDAå’Œnvcc
    cuda_ver, nvcc_ver = get_cuda_info()
    print(f"{'system_cuda'.ljust(15)}: {cuda_ver}")
    print(f"{'nvcc'.ljust(15)}: {nvcc_ver}")
    print("-" * 60)

if __name__ == "__main__":
    # è‡ªå®šä¹‰å›ºå®šé¡ºåºï¼šæŠŠdatasetså’Œaccelerateæ”¾åœ¨transformersä¹‹å
    CHECK_PACKAGES = [
        "numpy",
        "pandas",
        "torch",
        "torchvision",
        "torchaudio",
        "transformers",
        "datasets",
        "accelerate",
        "deepspeed",
        "langchain",
        "langchain-core",
        "langchain-community",
        "openai",
        "huggingface_hub",
        "llama-cpp-python",
        "langgraph",
        "jupyter",
        "protobuf",
        "chromadb",
        "opentelemetry-proto",
        "opentelemetry-exporter-otlp-proto-common",
        "opentelemetry-exporter-otlp-proto-grpc",
        "faiss-cpu",
        "pypdf",
        "python-docx",
        "tiktoken",
        "tokenizers",
        "sentence-transformers",
        "sentencepiece",
        "scikit-learn",
        "scipy",
        "jieba",
        "cpm_kernels",
        "nvitop"
        ]  
    # æŒ‰é€»è¾‘æ‰§è¡Œæ£€æµ‹ï¼ˆæ— ä»»ä½•è­¦å‘Šè¾“å‡ºï¼‰
    get_python_basic_info()
    batch_check_packages(CHECK_PACKAGES)
    check_pytorch_cuda_status()
    print("\nâœ… æ‰€æœ‰ç‰ˆæœ¬æ£€æµ‹å®Œæˆï¼")

